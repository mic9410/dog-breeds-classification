{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznawanie ras psów z wykorzystaniem biblioteki Keras\n",
    "### Michał Foryt, Szczepan Gabiec, Paweł Wróblewski\n",
    "\n",
    "<img src=\"meme2.jpg\" style=\"width: 400px;\">\n",
    "\n",
    "Celem projektu jest stworzenie algorytmu służącego do rozpoznawaniu ras psów porzy wykorzystaniu biblioteki Keras, w oparciu o TensorFlow. Zbiór z którego korzystaliśmy pochodzi z jednego z konkursów zorganizowanych przez portal Kaggle i znajduje się pod tym linkiem: https://www.kaggle.com/c/dog-breed-identification. Z uwagi na jego rozmiar (~750MB) nie bedzie on dołączony bezpośrednio do kodu.  \n",
    "\n",
    "W skład zbioru wchodzi około 10 tysięcy zdjęć, a wśród nich można wyróźnić 120 klas (ras psów). Pracując na tych danych, będziemy mogli stworzyć algorytm bazujący na głębokim uczeniu sieci neuronowych. W dużym uproszczeniu, zadaniem tego typu algorytmu jest rozpoznawanie obrazów podobnie, jak robi to umysł ludzki - \"oglądając\" ogromną pulę zdjęć z czasem rozpoznaje charakterystyczne cechy dla danego obiektu, przykładowo że rottweilera można poznać po tym, że jest duży i ma krótką, ciemną sierść, a york ma krótkie łapy i jest mocno owłosiony. Innymi słowy, algorytm najpierw zbiera dużą ilość danych, a następnie pozwala komputerowi zapoznać się z każdym z nich. Opierając się na dużych bazach danych i zauważając pojawiające się wzorce, komputery mogą rozpoznać obrazy i sformułować odpowiednie tagi i kategorie.\n",
    "\n",
    "Formalnie można nakreślić następujacy przebieg metody:\n",
    "- Na wejściu algorytm otrzymuje zbiór zawierający N obrazów, każdy z nich przypisany jest do jednej z K klas. \n",
    "- Następnie wykorzystuje się zbiór treningowy do szkolenia klasyfikatora tak, aby był on w stanie jak najepiej przyporządkować etykietę do zdjęcia.\n",
    "- Na koniec ocenia się jakość klasyfikatora, prosząc go o przewidywanie etykiet dla nowego zestawu obrazów, których nigdy wcześniej nie widział, po czym porównamy prawdziwe etykiety tych obrazów z przewidywanymi przez klasyfikator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucyjne Sieci Neuronowe \n",
    "Konwolucyjne Sieci Neuronowe (ang. <i>CNN, Convolutional neural networks</i>, tłumaczone także jako <i>Splotowe Sieci Neuronowe</i>) w sprytny sposób redukują liczbę przyjmowanych parametrów. Zamiast działać na sieci, w której neurony są połączone każdy z każdym, podejście jakie prezentują CNN wykorzystują wielokrotnie te same parametry. Kluczem do sukcesu konwolucyjnych sieci jest fakt, że wychodza one z założenia, że wystarczy lokalne zrozumienie obrazu. Innymi słowy, algorytm skupia się na tym, by  stopniowo filtrować różne części danych uczących i wyostrzać ważne cechy w procesie dyskryminacji wykorzystanym do rozpoznawania lub klasyfikacji wzorców. W praktyce zaletą takiego podejścia jest posiadanie mniejszej liczby parametrów, co przekłada się na znaczne zmniejszenie czasu potrzebnego do wytrenowania modelu.\n",
    "\n",
    "Rozważmy obraz o wymiarze 256 × 256 pikseli. Zamiast przetwarzać cały obraz naraz, CNN może skutecznie skanować go po kawałku - powiedzmy, patrząc na fragment o wymiarach 5 × 5. Taka ramka o wymiarach 5 × 5px przesuwa się wzdłuż obrazu (zwykle od lewej do prawej i od góry do dołu), jak pokazano na poniższym rysunku. \n",
    "\n",
    "<img src=\"cnn_concept.jpeg\" style=\"width: 350px;\">\n",
    "\n",
    "Tempo przesuwania się takiej ramki nazywamy \"długością kroku\". Na przykład długość kroku 2 oznacza, że okno 5 × 5 przesuwa się o 2 piksele na raz, aż obejmie cały obraz. Taka ramka 5 x 5 pikseli przekłada się na macierz wag o wymiarze 5 x 5. \n",
    "\n",
    "Tego typu operacja ma miejsce w warstwie konwolucyjnej sieci neuronowej. Typowa CNN posiada wiele tego typu warste. Każda z nich zazwyczaj generuje wiele różnych splotów (ang. <i>convolutions</i>). Co za tym idzie, macierz wagowa takiego tensora (czyli obiektu matematycznego będącego uogólnieniem pojęcia wektora) ma wymiary 5 × 5 x n, gdzie n liczbą konwolucji (splotów).\n",
    "\n",
    "Przykładowo, załóżmy że przepuszczamy rozważany obraz przez pojedynczą warstwę splotu jako macierz wagowa 5 x 5 x 64 z ramką 5 x 5. Co za ty idzie, taki model posiada 5 x 5 x64 = 1600 parametrów, podczas gdy pełna sieć dla obrazu 256 x 256px wymagałaby zastosowania 65 536 parametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obróbka zbioru danych\n",
    "Jak już wspomnielismy na początku, wykorzystamy zbiór danych dotyczący rozpoznawania ras psów, który wstępnie został już podzielony na zbiór treningowy i testowy. Nazwa każdego z obrazów jest też jednocześnie jego unikalnym id. Cały zestaw danych zawiera zdjęcia 120 ras, jednak dla urposzczenia modelu przyjmiemy założenie, że ograniczamy się jedynie do rozpoznawania 8 najpopularniejszych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla porządku, wszystkie niezbędne importy zastosujemy poniżej. Dzięki temu uzyskamy większa czytelność oraz podcas tworzenia naszej funkcjonalności będziemy mieli pewność, że wszystkie niezbędne paczki zostały już ściągnięte.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import scipy.misc\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import timedelta\n",
    "from scipy.stats import itemfreq\n",
    "from random import sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Otwarcie plików ZIP\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "\n",
    "# Obróbka zdjęć\n",
    "import PIL.Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie rozpakowujemy dane testowe i treningowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_test = ZipFile(\"dataset/test.zip\", 'r')\n",
    "archive_train = ZipFile(\"dataset/train.zip\", 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzamy czy dane zostały zaczytane poprawnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/',\n",
       " 'train/003df8b8a8b05244b1d920bb6cf451f9.jpg',\n",
       " 'train/0042188c895a2f14ef64a918ed9c7b64.jpg',\n",
       " 'train/00ba244566e36e0af3d979320fd3017f.jpg',\n",
       " 'train/00f34ac0a16ef43e6fd1de49a26081ce.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_train.namelist()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piszemy funkcję której zadaniem jest stworzenie Pickle files. Tego typu pliki wykorzystuje się do serializacji i de-serializacji obiektów w Pythonie. Każdy plik można poddać \"marynowaniu\" (\"piklowaniu\"), aby można go było zapisać na dysku. Pickling jest metodą która umożliwia serializację obiektu przed zapisaniem go do pliku. Pozwala zapisać obiekt pythonowy jako strumień znaków. Taka konstrukcja zawiera wszystkie informacje niezbędne do zrekonstruowania obiektu w innym skrypcie Pythona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istotną funkcją poniższego kodu jest znormalizowanie wymiarów zdjęć do porządanej wielkości tak, by wszystkie miały jeden rozmiar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_base_creator(archivezip, nwidth, nheight, save_name):\n",
    "    # Przygotowujemy pustą macierz zerową do której zapisywać będziemy dane o poszczególnych pikselach. \n",
    "    # Każdy obiekt w tablicy allImages zawiera listę pikseli, a każdy piksel reprezentowany jest przez\n",
    "    #listę 3-elementową, odpowiadającą wartości RGB\n",
    "    allImages = np.zeros((len(archivezip.namelist()[:])-1, nwidth, nheight, 3))\n",
    "\n",
    "    #Otwieramy każdy z obrazów, dostosowujemy rozmiar i zapisujemy \n",
    "    for i in range(1,len(archivezip.namelist()[:])):\n",
    "        filename = BytesIO(archivezip.read(archivezip.namelist()[i]))\n",
    "        image = PIL.Image.open(filename)\n",
    "        image = image.resize((nwidth, nheight))\n",
    "        image = np.array(image)\n",
    "        image = np.clip(image/255.0, 0.0, 1.0) # 255 = Maksymalna wartość w skali RGB dla piksela\n",
    "        allImages[i-1]=image\n",
    "    \n",
    "    # Zapisujemy nowo utworzoną bazę danych\n",
    "    pickle.dump(allImages, open( save_name + '.p', \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize = 60\n",
    "data_base_creator(archivezip = archive_train, nwidth = image_resize, nheight = image_resize, save_name = \"train\")\n",
    "data_base_creator(archivezip = archive_test, nwidth = image_resize, nheight = image_resize, save_name = \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
